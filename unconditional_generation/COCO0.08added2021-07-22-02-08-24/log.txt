{'data_path': 'data/MS_COCO_right', 'kenlm_path': './kenlm', 'save': 'COCO0.08added2021-07-22-02-08-24', 'maxlen': 16, 'vocab_size': 0, 'lowercase': True, 'emsize': 512, 'nhidden': 512, 'nlayers': 2, 'noise_r': 0.05, 'nheads': 4, 'nff': 1024, 'aehidden': 56, 'noise_anneal': 0.9995, 'hidden_init': False, 'arch_g': '300-300', 'arch_d': '300-300', 'arch_d_local': '300-300', 'z_size': 100, 'dropout': 0.3, 'noise_seq_length': 15, 'gan_type': 'kl', 'epochs': 100, 'min_epochs': 12, 'no_earlystopping': False, 'patience': 2, 'batch_size': 64, 'eval_batch_size': 32, 'niters_ae': 1, 'niters_gan_d': 1, 'niters_gan_dec': 1, 'niters_gan_g': 1, 'niters_gan_ae': 1, 'niters_gan_schedule': '', 'lr_ae': 0.08, 'lr_gan_e': 0.0001, 'lr_gan_g': 0.0004, 'lr_gan_d': 0.0001, 'beta1': 0.5, 'clip': 1, 'gan_clamp': 0.01, 'gan_gp_lambda': 1, 'gan_lambda': 0.1, 'add_noise': True, 'gan_d_local': True, 'gan_d_local_windowsize': 3, 'gan_g_activation': False, 'enhance_dec': True, 'sample': False, 'N': 5, 'log_interval': 200, 'seed': 1111, 'ntokens': 13548}
Training
| epoch   1 |     0/ 1835 batches | lr 0.000000 | ms/batch  0.61 | loss  0.05 | ppl     1.05 | acc     0.00 | train_ae_norm     1.00
[1/100][199/1835] Loss_D: 1.37946796 (Loss_D_real: 0.68775356 Loss_D_fake: 0.69171435) Loss_G: 0.00014069 Loss_Enh_Dec: -0.00072025
| epoch   1 |   200/ 1835 batches | lr 0.000000 | ms/batch 322.33 | loss  5.98 | ppl   395.32 | acc     0.27 | train_ae_norm     1.00
[1/100][399/1835] Loss_D: 1.38427711 (Loss_D_real: 0.69132805 Loss_D_fake: 0.69294906) Loss_G: 0.00010258 Loss_Enh_Dec: -0.00008139
| epoch   1 |   400/ 1835 batches | lr 0.000000 | ms/batch 329.90 | loss  4.88 | ppl   131.34 | acc     0.30 | train_ae_norm     1.00
[1/100][599/1835] Loss_D: 1.38238454 (Loss_D_real: 0.69230759 Loss_D_fake: 0.69007701) Loss_G: 0.00076554 Loss_Enh_Dec: 0.00013853
| epoch   1 |   600/ 1835 batches | lr 0.000000 | ms/batch 345.27 | loss  4.53 | ppl    92.95 | acc     0.33 | train_ae_norm     1.00
[1/100][799/1835] Loss_D: 1.38440061 (Loss_D_real: 0.69209945 Loss_D_fake: 0.69230115) Loss_G: 0.00046259 Loss_Enh_Dec: -0.00006594
| epoch   1 |   800/ 1835 batches | lr 0.000000 | ms/batch 338.31 | loss  4.38 | ppl    79.55 | acc     0.33 | train_ae_norm     1.00
[1/100][999/1835] Loss_D: 1.38488424 (Loss_D_real: 0.69287705 Loss_D_fake: 0.69200718) Loss_G: 0.00016460 Loss_Enh_Dec: -0.00018287
| epoch   1 |  1000/ 1835 batches | lr 0.000000 | ms/batch 346.33 | loss  4.23 | ppl    68.85 | acc     0.31 | train_ae_norm     1.00
[1/100][1199/1835] Loss_D: 1.38620996 (Loss_D_real: 0.69346207 Loss_D_fake: 0.69274783) Loss_G: 0.00018126 Loss_Enh_Dec: -0.00016167
| epoch   1 |  1200/ 1835 batches | lr 0.000000 | ms/batch 332.95 | loss  4.15 | ppl    63.19 | acc     0.37 | train_ae_norm     1.00
[1/100][1399/1835] Loss_D: 1.38523006 (Loss_D_real: 0.69259739 Loss_D_fake: 0.69263268) Loss_G: 0.00002444 Loss_Enh_Dec: -0.00009020
| epoch   1 |  1400/ 1835 batches | lr 0.000000 | ms/batch 327.97 | loss  4.06 | ppl    57.84 | acc     0.39 | train_ae_norm     1.00
[1/100][1599/1835] Loss_D: 1.38640094 (Loss_D_real: 0.69440746 Loss_D_fake: 0.69199347) Loss_G: 0.00009781 Loss_Enh_Dec: 0.00005657
| epoch   1 |  1600/ 1835 batches | lr 0.000000 | ms/batch 325.41 | loss  3.99 | ppl    53.95 | acc     0.35 | train_ae_norm     1.00
[1/100][1799/1835] Loss_D: 1.38626480 (Loss_D_real: 0.69261241 Loss_D_fake: 0.69365239) Loss_G: -0.00011990 Loss_Enh_Dec: -0.00019113
| epoch   1 |  1800/ 1835 batches | lr 0.000000 | ms/batch 335.49 | loss  3.94 | ppl    51.21 | acc     0.35 | train_ae_norm     1.00
| end of epoch   1 | time: 618.86s | test loss 593.69 | test ppl 689222720168366669092595848642539219674758927185034267808066570560616721466540450325329588936084057944618779599027044259031204472935488008921221384276830786978801676395294001964039548022760312039124071053034770075260625593327260742708113340788751252116733952.00 | acc 0.374
| epoch   2 |     0/ 1835 batches | lr 0.000000 | ms/batch  0.54 | loss  0.02 | ppl     1.02 | acc     0.38 | train_ae_norm     1.00
[2/100][199/1835] Loss_D: 1.38628292 (Loss_D_real: 0.69350278 Loss_D_fake: 0.69278008) Loss_G: -0.00003373 Loss_Enh_Dec: -0.00008309
| epoch   2 |   200/ 1835 batches | lr 0.000000 | ms/batch 332.16 | loss  3.86 | ppl    47.55 | acc     0.35 | train_ae_norm     1.00
[2/100][399/1835] Loss_D: 1.38522220 (Loss_D_real: 0.69295812 Loss_D_fake: 0.69226408) Loss_G: 0.00021460 Loss_Enh_Dec: 0.00008025
| epoch   2 |   400/ 1835 batches | lr 0.000000 | ms/batch 322.90 | loss  3.82 | ppl    45.63 | acc     0.36 | train_ae_norm     1.00
[2/100][599/1835] Loss_D: 1.38591218 (Loss_D_real: 0.69358718 Loss_D_fake: 0.69232500) Loss_G: 0.00004790 Loss_Enh_Dec: 0.00000390
| epoch   2 |   600/ 1835 batches | lr 0.000000 | ms/batch 341.30 | loss  3.77 | ppl    43.56 | acc     0.36 | train_ae_norm     1.00
[2/100][799/1835] Loss_D: 1.38531971 (Loss_D_real: 0.69292134 Loss_D_fake: 0.69239831) Loss_G: -0.00003396 Loss_Enh_Dec: -0.00004121
| epoch   2 |   800/ 1835 batches | lr 0.000000 | ms/batch 354.04 | loss  3.76 | ppl    43.12 | acc     0.37 | train_ae_norm     1.00
[2/100][999/1835] Loss_D: 1.38543439 (Loss_D_real: 0.69343555 Loss_D_fake: 0.69199878) Loss_G: 0.00017114 Loss_Enh_Dec: 0.00000145
| epoch   2 |  1000/ 1835 batches | lr 0.000000 | ms/batch 335.96 | loss  3.72 | ppl    41.06 | acc     0.34 | train_ae_norm     1.00
[2/100][1199/1835] Loss_D: 1.38562298 (Loss_D_real: 0.69281757 Loss_D_fake: 0.69280541) Loss_G: 0.00000462 Loss_Enh_Dec: 0.00011755
| epoch   2 |  1200/ 1835 batches | lr 0.000000 | ms/batch 339.80 | loss  3.69 | ppl    40.21 | acc     0.41 | train_ae_norm     1.00
[2/100][1399/1835] Loss_D: 1.38486218 (Loss_D_real: 0.69205999 Loss_D_fake: 0.69280213) Loss_G: -0.00013800 Loss_Enh_Dec: -0.00027278
| epoch   2 |  1400/ 1835 batches | lr 0.000000 | ms/batch 322.09 | loss  3.67 | ppl    39.43 | acc     0.43 | train_ae_norm     1.00
[2/100][1599/1835] Loss_D: 1.38740349 (Loss_D_real: 0.69248128 Loss_D_fake: 0.69492221) Loss_G: -0.00019963 Loss_Enh_Dec: -0.00036168
| epoch   2 |  1600/ 1835 batches | lr 0.000000 | ms/batch 328.62 | loss  3.65 | ppl    38.36 | acc     0.37 | train_ae_norm     1.00
[2/100][1799/1835] Loss_D: 1.38461041 (Loss_D_real: 0.69331408 Loss_D_fake: 0.69129634) Loss_G: -0.00007781 Loss_Enh_Dec: -0.00001606
| epoch   2 |  1800/ 1835 batches | lr 0.000000 | ms/batch 333.02 | loss  3.63 | ppl    37.63 | acc     0.38 | train_ae_norm     1.00
| end of epoch   2 | time: 618.86s | test loss 553.57 | test ppl 2583848178817180512763026192036560262235962912386826389963831519960322229526684538966292007831734154228001960099928287498526290970471855597371860514024090935099839019168345666956218101041937570418162864115171446661972992139253890676435189760.00 | acc 0.393
| epoch   3 |     0/ 1835 batches | lr 0.000000 | ms/batch  0.25 | loss  0.02 | ppl     1.02 | acc     0.40 | train_ae_norm     1.00
[3/100][199/1835] Loss_D: 1.38244462 (Loss_D_real: 0.69119847 Loss_D_fake: 0.69124615) Loss_G: -0.00061441 Loss_Enh_Dec: -0.00079241
| epoch   3 |   200/ 1835 batches | lr 0.000000 | ms/batch 335.90 | loss  3.59 | ppl    36.29 | acc     0.36 | train_ae_norm     1.00
[3/100][399/1835] Loss_D: 1.38293743 (Loss_D_real: 0.69177550 Loss_D_fake: 0.69116187) Loss_G: -0.00116239 Loss_Enh_Dec: -0.00123003
| epoch   3 |   400/ 1835 batches | lr 0.000000 | ms/batch 332.89 | loss  3.57 | ppl    35.68 | acc     0.38 | train_ae_norm     1.00
[3/100][599/1835] Loss_D: 1.38148499 (Loss_D_real: 0.69140708 Loss_D_fake: 0.69007790) Loss_G: -0.00171974 Loss_Enh_Dec: -0.00140885
| epoch   3 |   600/ 1835 batches | lr 0.000000 | ms/batch 329.15 | loss  3.54 | ppl    34.63 | acc     0.39 | train_ae_norm     1.00
[3/100][799/1835] Loss_D: 1.38096118 (Loss_D_real: 0.69207162 Loss_D_fake: 0.68888950) Loss_G: -0.00244302 Loss_Enh_Dec: -0.00250710
| epoch   3 |   800/ 1835 batches | lr 0.000000 | ms/batch 331.23 | loss  3.55 | ppl    34.85 | acc     0.38 | train_ae_norm     1.00
[3/100][999/1835] Loss_D: 1.37836981 (Loss_D_real: 0.69094133 Loss_D_fake: 0.68742841) Loss_G: -0.00195911 Loss_Enh_Dec: -0.00241829
| epoch   3 |  1000/ 1835 batches | lr 0.000000 | ms/batch 351.46 | loss  3.52 | ppl    33.93 | acc     0.37 | train_ae_norm     1.00
[3/100][1199/1835] Loss_D: 1.37401009 (Loss_D_real: 0.68642461 Loss_D_fake: 0.68758547) Loss_G: -0.00247222 Loss_Enh_Dec: -0.00309438
| epoch   3 |  1200/ 1835 batches | lr 0.000000 | ms/batch 339.13 | loss  3.51 | ppl    33.59 | acc     0.43 | train_ae_norm     1.00
[3/100][1399/1835] Loss_D: 1.35979164 (Loss_D_real: 0.68360150 Loss_D_fake: 0.67619014) Loss_G: -0.00244539 Loss_Enh_Dec: -0.00399863
| epoch   3 |  1400/ 1835 batches | lr 0.000000 | ms/batch 344.72 | loss  3.50 | ppl    33.01 | acc     0.43 | train_ae_norm     1.00
[3/100][1599/1835] Loss_D: 1.34639394 (Loss_D_real: 0.67441034 Loss_D_fake: 0.67198360) Loss_G: -0.00445401 Loss_Enh_Dec: -0.00498412
| epoch   3 |  1600/ 1835 batches | lr 0.000000 | ms/batch 334.73 | loss  3.48 | ppl    32.59 | acc     0.37 | train_ae_norm     1.00
[3/100][1799/1835] Loss_D: 1.34584999 (Loss_D_real: 0.68867165 Loss_D_fake: 0.65717840) Loss_G: -0.01144814 Loss_Enh_Dec: -0.00946956
| epoch   3 |  1800/ 1835 batches | lr 0.000000 | ms/batch 331.65 | loss  3.47 | ppl    32.28 | acc     0.39 | train_ae_norm     1.00
| end of epoch   3 | time: 624.41s | test loss 534.11 | test ppl 9112016224038111362936021034526915238228612777261630745596690811221421577676273862804306957535147606201979794613103316963114191721248998439364216324349547520898056659782153514927343902164397897549900511245936324381759396971565547520.00 | acc 0.402
| epoch   4 |     0/ 1835 batches | lr 0.000000 | ms/batch  0.36 | loss  0.02 | ppl     1.02 | acc     0.42 | train_ae_norm     1.00
[4/100][199/1835] Loss_D: 1.31967127 (Loss_D_real: 0.65661681 Loss_D_fake: 0.66305447) Loss_G: -0.01731052 Loss_Enh_Dec: -0.01631380
| epoch   4 |   200/ 1835 batches | lr 0.000000 | ms/batch 336.24 | loss  3.44 | ppl    31.26 | acc     0.39 | train_ae_norm     1.00
[4/100][399/1835] Loss_D: 1.29547703 (Loss_D_real: 0.64265490 Loss_D_fake: 0.65282214) Loss_G: -0.01296022 Loss_Enh_Dec: -0.01792316
| epoch   4 |   400/ 1835 batches | lr 0.000000 | ms/batch 330.41 | loss  3.42 | ppl    30.67 | acc     0.38 | train_ae_norm     1.00
[4/100][599/1835] Loss_D: 1.31170654 (Loss_D_real: 0.65931726 Loss_D_fake: 0.65238923) Loss_G: -0.01793547 Loss_Enh_Dec: -0.01419301
| epoch   4 |   600/ 1835 batches | lr 0.000000 | ms/batch 336.91 | loss  3.40 | ppl    29.88 | acc     0.39 | train_ae_norm     1.00
[4/100][799/1835] Loss_D: 1.30441749 (Loss_D_real: 0.66743374 Loss_D_fake: 0.63698375) Loss_G: -0.01805213 Loss_Enh_Dec: -0.01959796
| epoch   4 |   800/ 1835 batches | lr 0.000000 | ms/batch 359.34 | loss  3.41 | ppl    30.21 | acc     0.40 | train_ae_norm     1.00
[4/100][999/1835] Loss_D: 1.22861969 (Loss_D_real: 0.60065591 Loss_D_fake: 0.62796378) Loss_G: -0.03786261 Loss_Enh_Dec: -0.03679125
| epoch   4 |  1000/ 1835 batches | lr 0.000000 | ms/batch 368.13 | loss  3.39 | ppl    29.61 | acc     0.37 | train_ae_norm     1.00
[4/100][1199/1835] Loss_D: 1.28421640 (Loss_D_real: 0.65466541 Loss_D_fake: 0.62955105) Loss_G: -0.02713377 Loss_Enh_Dec: -0.03103103
| epoch   4 |  1200/ 1835 batches | lr 0.000000 | ms/batch 371.02 | loss  3.39 | ppl    29.55 | acc     0.44 | train_ae_norm     1.00
[4/100][1399/1835] Loss_D: 1.18981576 (Loss_D_real: 0.58315176 Loss_D_fake: 0.60666400) Loss_G: -0.02094207 Loss_Enh_Dec: -0.05578838
| epoch   4 |  1400/ 1835 batches | lr 0.000000 | ms/batch 349.93 | loss  3.37 | ppl    29.17 | acc     0.43 | train_ae_norm     1.00
[4/100][1599/1835] Loss_D: 1.30793583 (Loss_D_real: 0.69283473 Loss_D_fake: 0.61510110) Loss_G: -0.05068399 Loss_Enh_Dec: -0.06116727
| epoch   4 |  1600/ 1835 batches | lr 0.000000 | ms/batch 369.96 | loss  3.36 | ppl    28.80 | acc     0.41 | train_ae_norm     1.00
[4/100][1799/1835] Loss_D: 1.23098195 (Loss_D_real: 0.59689748 Loss_D_fake: 0.63408446) Loss_G: -0.04406158 Loss_Enh_Dec: -0.05586655
| epoch   4 |  1800/ 1835 batches | lr 0.000000 | ms/batch 372.31 | loss  3.36 | ppl    28.72 | acc     0.39 | train_ae_norm     1.00
| end of epoch   4 | time: 656.89s | test loss 519.42 | test ppl 3794821140616978315427562585384730132237614576970752579451897225176188435833185020840801471349634266797623697427774821956159742783614077725117707305842762354701179217494118084347693016362630436231222754654117999774827634753536.00 | acc 0.408
bleu_self: [1.00000000,1.00000000,1.00000000,1.00000000,1.00000000]
bleu_test: [1.00000000,1.00000000,1.00000000,1.00000000,0.95797800]
| epoch   5 |     0/ 1835 batches | lr 0.000000 | ms/batch  0.52 | loss  0.02 | ppl     1.02 | acc     0.42 | train_ae_norm     1.00
[5/100][199/1835] Loss_D: 1.17541265 (Loss_D_real: 0.57108611 Loss_D_fake: 0.60432661) Loss_G: -0.03514767 Loss_Enh_Dec: -0.06881707
| epoch   5 |   200/ 1835 batches | lr 0.000000 | ms/batch 363.40 | loss  3.34 | ppl    28.15 | acc     0.37 | train_ae_norm     1.00
[5/100][399/1835] Loss_D: 1.20125127 (Loss_D_real: 0.53303075 Loss_D_fake: 0.66822046) Loss_G: -0.05455818 Loss_Enh_Dec: -0.06593161
| epoch   5 |   400/ 1835 batches | lr 0.000000 | ms/batch 367.14 | loss  3.33 | ppl    27.86 | acc     0.41 | train_ae_norm     1.00
[5/100][599/1835] Loss_D: 1.18725455 (Loss_D_real: 0.63812613 Loss_D_fake: 0.54912841) Loss_G: -0.10890766 Loss_Enh_Dec: -0.12032498
| epoch   5 |   600/ 1835 batches | lr 0.000000 | ms/batch 346.18 | loss  3.31 | ppl    27.26 | acc     0.42 | train_ae_norm     1.00
[5/100][799/1835] Loss_D: 1.12331533 (Loss_D_real: 0.57724547 Loss_D_fake: 0.54606986) Loss_G: -0.15045238 Loss_Enh_Dec: -0.08681976
| epoch   5 |   800/ 1835 batches | lr 0.000000 | ms/batch 347.99 | loss  3.32 | ppl    27.59 | acc     0.40 | train_ae_norm     1.00
[5/100][999/1835] Loss_D: 1.13069499 (Loss_D_real: 0.57539713 Loss_D_fake: 0.55529785) Loss_G: -0.08130755 Loss_Enh_Dec: -0.10624670
| epoch   5 |  1000/ 1835 batches | lr 0.000000 | ms/batch 382.91 | loss  3.30 | ppl    27.08 | acc     0.39 | train_ae_norm     1.00
[5/100][1199/1835] Loss_D: 1.09537792 (Loss_D_real: 0.51952600 Loss_D_fake: 0.57585192) Loss_G: -0.04266891 Loss_Enh_Dec: -0.07909364
| epoch   5 |  1200/ 1835 batches | lr 0.000000 | ms/batch 381.81 | loss  3.30 | ppl    27.02 | acc     0.45 | train_ae_norm     1.00
[5/100][1399/1835] Loss_D: 1.10669827 (Loss_D_real: 0.50781417 Loss_D_fake: 0.59888411) Loss_G: -0.04873640 Loss_Enh_Dec: -0.07546153
| epoch   5 |  1400/ 1835 batches | lr 0.000000 | ms/batch 365.26 | loss  3.29 | ppl    26.80 | acc     0.44 | train_ae_norm     1.00
[5/100][1599/1835] Loss_D: 1.14822292 (Loss_D_real: 0.52616274 Loss_D_fake: 0.62206018) Loss_G: -0.07441919 Loss_Enh_Dec: -0.08959334
| epoch   5 |  1600/ 1835 batches | lr 0.000000 | ms/batch 361.91 | loss  3.28 | ppl    26.64 | acc     0.40 | train_ae_norm     1.00
[5/100][1799/1835] Loss_D: 1.05488050 (Loss_D_real: 0.49485007 Loss_D_fake: 0.56003046) Loss_G: -0.06891046 Loss_Enh_Dec: -0.08323660
| epoch   5 |  1800/ 1835 batches | lr 0.000000 | ms/batch 361.38 | loss  3.27 | ppl    26.44 | acc     0.42 | train_ae_norm     1.00
| end of epoch   5 | time: 673.29s | test loss 510.11 | test ppl 345653524796885437928360661396607515217672666590500254114130974678103899249919333814817574192860404176255468791589028725856574765676696689241613062476847229410514359898490778388120037925452043969921384893127802558808588288.00 | acc 0.412
bleu_self: [1.00000000,1.00000000,1.00000000,1.00000000,1.00000000]
bleu_test: [1.00000000,1.00000000,0.95646559,0.93060486,0.87055056]
| epoch   6 |     0/ 1835 batches | lr 0.000000 | ms/batch  0.52 | loss  0.02 | ppl     1.02 | acc     0.44 | train_ae_norm     1.00
[6/100][199/1835] Loss_D: 0.99191070 (Loss_D_real: 0.51732469 Loss_D_fake: 0.47458601) Loss_G: -0.03491780 Loss_Enh_Dec: -0.06346159
| epoch   6 |   200/ 1835 batches | lr 0.000000 | ms/batch 348.12 | loss  3.26 | ppl    26.04 | acc     0.39 | train_ae_norm     1.00
[6/100][399/1835] Loss_D: 1.04944777 (Loss_D_real: 0.51103634 Loss_D_fake: 0.53841138) Loss_G: -0.06446942 Loss_Enh_Dec: -0.06395914
| epoch   6 |   400/ 1835 batches | lr 0.000000 | ms/batch 338.92 | loss  3.25 | ppl    25.86 | acc     0.40 | train_ae_norm     1.00
[6/100][599/1835] Loss_D: 0.94827425 (Loss_D_real: 0.47271523 Loss_D_fake: 0.47555900) Loss_G: -0.05880952 Loss_Enh_Dec: -0.04495600
| epoch   6 |   600/ 1835 batches | lr 0.000000 | ms/batch 339.96 | loss  3.23 | ppl    25.34 | acc     0.41 | train_ae_norm     1.00
[6/100][799/1835] Loss_D: 1.03169632 (Loss_D_real: 0.52103925 Loss_D_fake: 0.51065701) Loss_G: -0.04136365 Loss_Enh_Dec: -0.05234961
| epoch   6 |   800/ 1835 batches | lr 0.000000 | ms/batch 336.19 | loss  3.25 | ppl    25.67 | acc     0.42 | train_ae_norm     1.00
[6/100][999/1835] Loss_D: 0.95175099 (Loss_D_real: 0.48490056 Loss_D_fake: 0.46685040) Loss_G: -0.01322900 Loss_Enh_Dec: -0.04899289
| epoch   6 |  1000/ 1835 batches | lr 0.000000 | ms/batch 354.51 | loss  3.23 | ppl    25.31 | acc     0.38 | train_ae_norm     1.00
[6/100][1199/1835] Loss_D: 0.95671356 (Loss_D_real: 0.42092708 Loss_D_fake: 0.53578645) Loss_G: -0.06097640 Loss_Enh_Dec: -0.09579604
| epoch   6 |  1200/ 1835 batches | lr 0.000000 | ms/batch 306.08 | loss  3.23 | ppl    25.38 | acc     0.43 | train_ae_norm     1.00
[6/100][1399/1835] Loss_D: 0.98828614 (Loss_D_real: 0.47204021 Loss_D_fake: 0.51624590) Loss_G: -0.03195928 Loss_Enh_Dec: -0.06383492
| epoch   6 |  1400/ 1835 batches | lr 0.000000 | ms/batch 303.60 | loss  3.23 | ppl    25.18 | acc     0.46 | train_ae_norm     1.00
[6/100][1599/1835] Loss_D: 0.96708858 (Loss_D_real: 0.40423259 Loss_D_fake: 0.56285596) Loss_G: -0.02958567 Loss_Enh_Dec: -0.04087247
| epoch   6 |  1600/ 1835 batches | lr 0.000000 | ms/batch 336.50 | loss  3.22 | ppl    24.99 | acc     0.40 | train_ae_norm     1.00
