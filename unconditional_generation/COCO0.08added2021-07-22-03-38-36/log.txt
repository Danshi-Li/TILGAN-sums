{'data_path': 'data/MS_COCO_right', 'kenlm_path': './kenlm', 'save': 'COCO0.08added2021-07-22-03-38-36', 'maxlen': 16, 'vocab_size': 0, 'lowercase': True, 'emsize': 512, 'nhidden': 512, 'nlayers': 2, 'noise_r': 0.05, 'nheads': 4, 'nff': 1024, 'aehidden': 56, 'noise_anneal': 0.9995, 'hidden_init': False, 'arch_g': '300-300', 'arch_d': '300-300', 'arch_d_local': '300-300', 'z_size': 100, 'dropout': 0.3, 'noise_seq_length': 15, 'gan_type': 'kl', 'epochs': 100, 'min_epochs': 12, 'no_earlystopping': False, 'patience': 2, 'batch_size': 64, 'eval_batch_size': 32, 'niters_ae': 1, 'niters_gan_d': 1, 'niters_gan_dec': 1, 'niters_gan_g': 1, 'niters_gan_ae': 1, 'niters_gan_schedule': '', 'lr_ae': 0.08, 'lr_gan_e': 0.0001, 'lr_gan_g': 0.0004, 'lr_gan_d': 0.0001, 'beta1': 0.5, 'clip': 1, 'gan_clamp': 0.01, 'gan_gp_lambda': 1, 'gan_lambda': 0.1, 'add_noise': True, 'gan_d_local': True, 'gan_d_local_windowsize': 3, 'gan_g_activation': False, 'enhance_dec': True, 'sample': False, 'N': 5, 'log_interval': 200, 'seed': 1111, 'ntokens': 13548}
Training
| epoch   1 |     0/ 1835 batches | lr 0.000000 | ms/batch  1.89 | loss  0.05 | ppl     1.05 | acc     0.00 | train_ae_norm     1.00
[1/100][199/1835] Loss_D: 1.37946796 (Loss_D_real: 0.68775356 Loss_D_fake: 0.69171435) Loss_G: 0.00014069 Loss_Enh_Dec: -0.00072025
| epoch   1 |   200/ 1835 batches | lr 0.000000 | ms/batch 328.23 | loss  5.98 | ppl   395.32 | acc     0.27 | train_ae_norm     1.00
[1/100][399/1835] Loss_D: 1.38427711 (Loss_D_real: 0.69132805 Loss_D_fake: 0.69294906) Loss_G: 0.00010258 Loss_Enh_Dec: -0.00008139
| epoch   1 |   400/ 1835 batches | lr 0.000000 | ms/batch 329.95 | loss  4.88 | ppl   131.34 | acc     0.30 | train_ae_norm     1.00
[1/100][599/1835] Loss_D: 1.38238454 (Loss_D_real: 0.69230759 Loss_D_fake: 0.69007701) Loss_G: 0.00076554 Loss_Enh_Dec: 0.00013853
| epoch   1 |   600/ 1835 batches | lr 0.000000 | ms/batch 339.46 | loss  4.53 | ppl    92.95 | acc     0.33 | train_ae_norm     1.00
[1/100][799/1835] Loss_D: 1.38440061 (Loss_D_real: 0.69209945 Loss_D_fake: 0.69230115) Loss_G: 0.00046259 Loss_Enh_Dec: -0.00006594
| epoch   1 |   800/ 1835 batches | lr 0.000000 | ms/batch 320.00 | loss  4.38 | ppl    79.55 | acc     0.33 | train_ae_norm     1.00
[1/100][999/1835] Loss_D: 1.38488424 (Loss_D_real: 0.69287705 Loss_D_fake: 0.69200718) Loss_G: 0.00016460 Loss_Enh_Dec: -0.00018287
| epoch   1 |  1000/ 1835 batches | lr 0.000000 | ms/batch 316.91 | loss  4.23 | ppl    68.85 | acc     0.31 | train_ae_norm     1.00
[1/100][1199/1835] Loss_D: 1.38620996 (Loss_D_real: 0.69346207 Loss_D_fake: 0.69274783) Loss_G: 0.00018126 Loss_Enh_Dec: -0.00016167
| epoch   1 |  1200/ 1835 batches | lr 0.000000 | ms/batch 305.92 | loss  4.15 | ppl    63.19 | acc     0.37 | train_ae_norm     1.00
[1/100][1399/1835] Loss_D: 1.38523006 (Loss_D_real: 0.69259739 Loss_D_fake: 0.69263268) Loss_G: 0.00002444 Loss_Enh_Dec: -0.00009020
| epoch   1 |  1400/ 1835 batches | lr 0.000000 | ms/batch 315.17 | loss  4.06 | ppl    57.84 | acc     0.39 | train_ae_norm     1.00
[1/100][1599/1835] Loss_D: 1.38640094 (Loss_D_real: 0.69440746 Loss_D_fake: 0.69199347) Loss_G: 0.00009781 Loss_Enh_Dec: 0.00005657
| epoch   1 |  1600/ 1835 batches | lr 0.000000 | ms/batch 297.93 | loss  3.99 | ppl    53.95 | acc     0.35 | train_ae_norm     1.00
[1/100][1799/1835] Loss_D: 1.38626480 (Loss_D_real: 0.69261241 Loss_D_fake: 0.69365239) Loss_G: -0.00011990 Loss_Enh_Dec: -0.00019113
| epoch   1 |  1800/ 1835 batches | lr 0.000000 | ms/batch 290.35 | loss  3.94 | ppl    51.21 | acc     0.35 | train_ae_norm     1.00
| end of epoch   1 | time: 586.29s | test loss 593.69 | test ppl 689222720168366669092595848642539219674758927185034267808066570560616721466540450325329588936084057944618779599027044259031204472935488008921221384276830786978801676395294001964039548022760312039124071053034770075260625593327260742708113340788751252116733952.00 | acc 0.374
| epoch   2 |     0/ 1835 batches | lr 0.000000 | ms/batch  0.38 | loss  0.02 | ppl     1.02 | acc     0.38 | train_ae_norm     1.00
