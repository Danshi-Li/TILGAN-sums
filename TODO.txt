###Next step to modification of TILGAN code###
1.Change the encoder backbone to a BERT pretrained model
2.Change the decoder backbone to a GPT pretrained model

###What to do inorder to implement them###
Revise the "Seq2Seq" class in the "models.py" file. Note that only one submodule should be modified in each progressive step, which enhances ablation analysis.
In specific, should separately revise two new versions of file:
File 1 only substitutes the encoder and File 2 only substitutes the decoder. After each file is tested for viability, combine their respective revisions and commit the final version.


###Debugging issue###
At the time being the input representation does not match the requirement of BERT model.
Need to stop randomly trying and thoroughly study how things are defined in HF\src and how examples in HF\examples work.
Besides, find other papers where BERT+GPT architecture is implemented, because those have solved problems we are to meet up with.

No cursory work and take every step solid.
